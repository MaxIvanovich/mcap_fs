# Импорт необходимых библиотек ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import numpy as np
import scipy.special as sc
#import matplotlib.pyplot as mp
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Определение класса нейронной сети ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
class NN:

    # Функция инициализации нейронной сети ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):

        # Количество узлов на входном, скрытом и выходном слоях ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
        self.inodes = inputnodes
        self.hnodes = hiddennodes
        self.onodes = outputnodes

        # Коэффициент обучения ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
        self.lr = learningrate

        # Матрицы весовых коэффициентов связей ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
        # при инициализации заполняются случайными числами с нормальным распределением
        #   wih - между входным и скрытым слоями
        #   who - между скрытым и выходным слоями
        # numpy.random.normal(loc=0.0, scale=1.0, size=None) - метод, возвращающий случайные числа
        # по нормальному (Гаусову) распределению, параметры которого:
        #   loc - "центр" распределения, в нашем случае 0.0
        #   scale - стандартное отклонение (спред или "ширина"), в нашем случае величина
        # стандартного отклонения обратно пропорциональна квадратному корню из количества связей
        # на узел
        #   size - необязательный параметр, определяющий форму вывода функции, в нашем случае это
        # двумерная матрица с размерами (hnodes x inodes)
        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))
        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))

        # Функции активации:
        self.hidden_act_func = lambda x: sc.expit(x)    # сигмоида для скрытого слоя
        self.output_act_func = lambda x: np.tanh(x)     # гиперболический тангенс для выходного слоя
        
        pass
    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    # Функция тренировки нейронной сети ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    def train():
        pass
    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    # Функция опроса нейронной сети ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    def query():
        pass
    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Характеристики экземпляра класса нейронной сети ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# количество свечей для одного набора
candles_quantity = 5

# количество входных узлов (параметров) - 6 параметров свечей * 5 свечей + 1 нейрон смещения
input_nodes = 6 * candles_quantity + 1

# количество скрытых узлов - равно количеству входнх узлов + нейрон смещения
hidden_nodes = input_nodes

# количество выходных узлов
output_nodes = 1

# коэффициент обучения
learning_rate = 0.1 

nn = NN(input_nodes, hidden_nodes, output_nodes, learning_rate)

# Подготовка входящих тренировочных данных ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dataset_file = "./dataset/RI_extended.csv"

# Открытие файла с данными для чтения
dataset_file = open(dataset_file, "r", encoding="utf-8")

# Чтение всех строк из файла и закрытие файла
all_list = dataset_file.readlines()
dataset_file.close()

# Общее количество строк (каждая строка соответствует одной дневной свече)
total_candles = len(all_list)
# Разделение данных на две группы - тренировочную (~80%) и проверочную (~20%)
total_trainset = int(total_candles * 0.8)
total_testset = total_candles - total_trainset
print(total_trainset, total_testset)

print(all_list)